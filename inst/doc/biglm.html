<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Colin Gillespie" />


<title>Big linear models</title>






<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Big linear models</h1>
<h4 class="author"><em>Colin Gillespie</em></h4>



<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Big linear models}
-->
<p>Linear models (lm) are one of the most basic statistical models available. The simplest regression model is <span class="math display">\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]</span> where <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span>. This corresponds to fitting a straight line through some points. So <span class="math inline">\(\beta_0\)</span> is the <span class="math inline">\(y\)</span>-intercept and <span class="math inline">\(\beta_1\)</span> is the gradient. The aim is to estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<div class="figure">
<img src="data:image/png;base64,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" alt="Simple linear regression" />
<p class="caption">Simple linear regression</p>
</div>
<p>In the more general multiple regression model, there are <span class="math inline">\(p\)</span> predictor variables <span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} + \epsilon_i, 
\]</span> where <span class="math inline">\(x_{ij}\)</span> is the <span class="math inline">\(i^\text{th}\)</span> observation on the <span class="math inline">\(j^\text{th}\)</span> independent variable. The above equation can be written neatly in matrix notation as <span class="math display">\[
\mathbf{Y} = X \mathbf{\beta} + \mathbf{\epsilon}
\]</span> with dimensions <span class="math display">\[
[n\times 1]= [n\times (p+1)] ~[(p+1)\times 1] + [n \times 1 ]\;,
\]</span> where</p>
<ul>
<li><span class="math inline">\(\mathbf{Y}\)</span> is the response vector - (dimensions <span class="math inline">\(n \times 1\)</span>);</li>
<li><span class="math inline">\(X\)</span> is the design matrix - (dimensions <span class="math inline">\(n \times (p+1)\)</span>);</li>
<li><span class="math inline">\(\mathbf{\beta}\)</span> is the parameter vector - (dimensions <span class="math inline">\((p+1) \times 1\)</span>);</li>
<li><span class="math inline">\(\mathbf{\epsilon}\)</span> is the error vector - (dimensions <span class="math inline">\(n \times 1\)</span>).</li>
</ul>
<p>The goal of regression is to estimate <span class="math inline">\(\mathbf{\beta}\)</span> with <span class="math inline">\(\mathbf{\hat\beta}\)</span>. It can be shown that <span class="math display">\[
\mathbf{\hat\beta} = (X^T X)^{-1} X^T \mathbf{Y} \;.
\]</span> Our estimate of <span class="math inline">\(\mathbf{\hat \beta}\)</span> will exist provided that <span class="math inline">\((X^T X)^{-1}\)</span> exists, i.e. no column of <span class="math inline">\(X\)</span> is a linear combination of other columns. For a least squares regression with a sample size of <span class="math inline">\(n\)</span> training examples and <span class="math inline">\(p\)</span> predictors, it takes:</p>
<ul>
<li><span class="math inline">\(O(p^2n)\)</span> to multiply <span class="math inline">\(X^T\)</span> by <span class="math inline">\(X\)</span>;</li>
<li><span class="math inline">\(O(pn)\)</span> to multiply <span class="math inline">\(X^T\)</span> by <span class="math inline">\(\mathbf{Y}\)</span>;</li>
<li><span class="math inline">\(O(p^3)\)</span> to compute the LU (or Cholesky) factorization of <span class="math inline">\(X^TX\)</span> that is used to compute the product of <span class="math inline">\((X^TX)^{-1} (X^T\mathbf{Y})\)</span>.</li>
</ul>
<p>Since <span class="math inline">\(n &gt;&gt; p\)</span>, this means that the algorithm scales with order <span class="math inline">\(O(p^2 n)\)</span>. As well as taking a long time to calculate, the memory required also increases. The R implementation of  requires <span class="math inline">\(O(np + p^2)\)</span> in memory. But this can be reduced by constructing the model matrix in chunks. The ’s algorithm is based on algorithm <a href="http://lib.stat.cmu.edu/apstat/274">AS 274</a>. It works by updating the Cholesky decomposition with new observations. So for a model with <span class="math inline">\(p\)</span> variables, only the <span class="math inline">\(p \times p\)</span> (triangular) Cholesky factor and a single row of data needs to be in the memory at any given time. The <code>biglm</code> package does not do the chunking for you, but <code>ffbase</code> provides a handy S3 wrapper, <code>bigglm.ffdf</code>.</p>
<p>For an example of using , see the blog post at by <a href="http://goo.gl/iBPkTp">Bnosac</a>.</p>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
